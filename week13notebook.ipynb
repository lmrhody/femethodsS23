{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lmrhody/femethodsS23/blob/main/week13notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ipVnktW5Kek"
      },
      "source": [
        "# Week 13 Notebook: Analyzing Sentiment \n",
        "\n",
        "Name:\n",
        "\n",
        "Date:\n",
        "\n",
        "Class:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3imjy8U5Kel"
      },
      "source": [
        "## What is Sentiment Analysis? \n",
        "* opinion mining\n",
        "* The author's attitude toward the subject (tone). \n",
        "* Measuring emotion --> \n",
        "\n",
        "  - how much? \n",
        "  - directed toward? \n",
        "  - negation? \n",
        "\n",
        "Opinion / emotion are equated for the purpose of measuring in sentiment analysis. There is work by linguists on how to measure sarcasm, refining negation measures, etc. \n",
        "\n",
        "## 3 Elements of Sentiment \n",
        "### Opinion / Emotion\n",
        "#### Polarity\n",
        "    - positive (+)\n",
        "    - negative (-) \n",
        "    - sometimes though not often_ neutral (=)\n",
        "    \n",
        "#### Multi-class\n",
        "    - joy \n",
        "    - surprise\n",
        "    - anger \n",
        "    - love\n",
        "    \n",
        "#### Quantitative\n",
        "    - Likert scale\n",
        "    - rating\n",
        "    - numerical grading, number of likes, endorsements, etc. \n",
        "    \n",
        "### Subject\n",
        "    - What is discussed? \n",
        "        - Book, movie, song, product, service, teacher... \n",
        "    - Can be mixed \n",
        "        -  ie. I like the main character of the novel, but the plot was slow and the dialogue was flat. \n",
        "    - In other words, the level of granularity at which the sentiment is leveled becomes part of the test. \n",
        "        \n",
        "### Opinion Holder or Entity\n",
        "    - Who holds the opinion? \n",
        "    - What do we know about the opinion holder?\n",
        "    - How much does it matter? \n",
        "\n",
        "_Sentiment analysis does not work well with null values._\n",
        "    \n",
        "## How is Sentiment Analysis used\n",
        "Social listening is a job category in which people are paid to use data such as Amazon reviews, Twitter hashtags, Rate My Professor reviews, etc, and identify: what is discussed (including granularity), how is it being discussed (opinion equated to sentiment / emotion), and by whom is it being discussed. Sentiment analysis is performed on single sentences, single words, collections of words, social media datasets, but also blog posts, online forums, and the news. \n",
        "\n",
        "It is meant to _enrich_ an assessment of a brand and opinions held about it. The same tools have also been used for social science research, and literary studies. For example, Matthew Jocker's analysis of _forms of the novel_ using the Syuzhet Package (an R package described here: https://cran.r-project.org/web/packages/syuzhet/vignettes/syuzhet-vignette.html). \n",
        "\n",
        "## Question for reflection: How does \"sentiment analysis\" work in a rhetorical analysis? \n",
        "Consider how we approach questions of \"sentiment\" (arguably, tone) in a close reading \"rhetorial analysis\" and what the slippages might be between that form of close reading analysis of sentiment and the \"operationalized\" reading that measures language's sentimental or emotional weight. \n",
        "\n",
        "\n",
        "## Question for reflection: Consider what it means to bring a metric and method designed for consumer research into the humanities? What are the potential advantages or disadvantages of doing so? \n",
        "You might consider as a starting off point that many scholars, especially Marxist scholars, of text have pointed to the tensions between market value of texts (consumer interest, purchasing, annd production) and the _literary tastes_ of \"high fiction.\" Or, one might consider the tensions between mass market production of books and reader reception theory in conversation with the marketing and reception or \"literariness\" of small press literary production. \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dnYpSbNS5Kem"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "McGlNAlh5Ken"
      },
      "outputs": [],
      "source": [
        "# import dataset (a sample from IMDB)\n",
        "movies = 'IMDB_sample.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e-oInFc25Ken"
      },
      "outputs": [],
      "source": [
        "# convert the IMDB comma separated values file into a pandas dataframe\n",
        "movies_df = pd.read_csv(movies)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jGZSwRrj5Keo",
        "outputId": "abeb0198-ef96-4d6e-883d-70b7c5364482"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>review</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>18245</td>\n",
              "      <td>This short spoof can be found on Elite's Mille...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>19801</td>\n",
              "      <td>A singularly unfunny musical comedy that artif...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3222</td>\n",
              "      <td>An excellent series, masterfully acted and dir...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6010</td>\n",
              "      <td>The master of movie spectacle Cecil B. De Mill...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>16355</td>\n",
              "      <td>I was gifted with this movie as it had such a ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0                                             review  label\n",
              "0       18245  This short spoof can be found on Elite's Mille...      0\n",
              "1       19801  A singularly unfunny musical comedy that artif...      0\n",
              "2        3222  An excellent series, masterfully acted and dir...      1\n",
              "3        6010  The master of movie spectacle Cecil B. De Mill...      1\n",
              "4       16355  I was gifted with this movie as it had such a ...      0"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Let's look at how the dataframe is organized by displaying the first 5 entries. \n",
        "\n",
        "movies_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sId2Q0TT5Keo"
      },
      "source": [
        "Ok, so when we're looking at this dataframe, what do we see? Each row has a unique identifier, which begins with 0. There is also an unnamed label. This number is probably either the number of the review or the number of characters, but we don't know b/c it's not labeled. Then, the text of the review can be found in the \"review\" column. Finally, the \"label\" colum holds a series of 0s and 1s. These 0s and 1s represent _polarity_ data. That is to say that it is a binary distinction between \"positive\" (1) and \"negative\" (0) reviews. The word \"label\" is confusing, because \"reviews\" is, technically also a label. Try not to get hung up there. But for now, the \"label\" label is where we know that the \"sentiment\" measure is held. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9VBfRoSo5Kep",
        "outputId": "7eb95856-c237-4780-8bca-18aac0eead01"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    3782\n",
              "1    3719\n",
              "Name: label, dtype: int64"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# What if we wanted to know how many \"positive\" and \"negative\" reviews are in the dataset? \n",
        "# We'd call the name of the dataframe, we'd name the column that we want to perform an action on. We'd then say what\n",
        "# action we'd like to perform. Here, value_counts will count the total number of each value and give you the totals.\n",
        "# It will also tell you what \"data type\" you are counting. If you want to eventually do a sentiment analysis, \n",
        "# you would want an even distribution. So, this is a layer of exploratory work before you can get started. \n",
        "\n",
        "movies_df.label.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nSyHfCfa5Kep",
        "outputId": "a87de311-365d-4d6e-883d-f5ded56c9e69"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    0.504199\n",
              "1    0.495801\n",
              "Name: label, dtype: float64"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# So, you know the numbers... but maybe it's hard to tell whether or not the two groups of data are proportionate. \n",
        "# Another way to look at your data would be to turn those label values into proportions. We do that by creating\n",
        "# a mathematical equation. This says, take the label column from the movies dataframe and count the values for each\n",
        "# unique label. Then, divide those numbers by the total number of rows in the movies_df dataframe. Here's how that looks:\n",
        "\n",
        "movies_df.label.value_counts()/len(movies_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EcOdPYQX5Kep"
      },
      "outputs": [],
      "source": [
        "# Look back at the dataframe. What is the degree of granularity at which each review is assigned a sentimental value? \n",
        "# Do you have any thoughts about whether or not the length of a review relates to the amount of sentiment that might\n",
        "# be found in side? Well, one thing you might want to do is to figure out how long the longest review is. \n",
        "# We do this by cfreating a pandas series. We're taking the reviews column from the movies dataframe. We are defining\n",
        "# the data type as a string (str), and then we are calculating the length of each.\n",
        "\n",
        "length_reviews = movies_df.review.str.len()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CPoUa0CT5Kep",
        "outputId": "28ede09b-9a58-4dbd-a53f-80504be31c57"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "pandas.core.series.Series"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# The output when we do this is called a \"series.\"\n",
        "type(length_reviews)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1bGEKDHF5Keq",
        "outputId": "4232dc8e-b077-4a76-a1b3-55a39bb2c189"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "10321"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# We can use the \"max\" function to search the dataframe and then to find how many characters are in the longest review\n",
        "max(length_reviews)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-xsnvp455Keq",
        "outputId": "c8c821c0-ec82-4ac2-8c9f-3a33fb99035c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "52"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Same thing for the shortest review. \n",
        "min(length_reviews)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgRBrFPD5Keq"
      },
      "source": [
        "If we believe that the length of the review is a valuable feature that we want to continue working with, we could append this information to the dataframe. If you want to continue learning outside of class, this is a good challenge problem to work on. See if you can take this new data about each review and add it as an additional \"feature\" in your dataset. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9zJilLO5Keq"
      },
      "source": [
        "## Exploring Data in Detail\n",
        "\n",
        "### Levels of granularity\n",
        "Measuring \"sentiment\" this way is highly dependent on how closely you want to look at the text.\n",
        "* Document level?\n",
        "* Sentence level? \n",
        "* Aspect level? (relating sentiment to a direct referent, even within a single statement)\n",
        "\n",
        "### Types of Sentiment Analysis\n",
        "In general, there are two kinds of sentiment analysis.\n",
        "#### Rule or Lexicon-based\n",
        "In this approach, algorithms match the words in the lexicon to the dataset and eitheer sums the whole or averages them, depending on what function you choose. The result is a combinatory values. In other words, the reviews above are measured in 1/0 because they are a \"net positive\" or \"net negative\"--and the algorithm assignes the value based on where the total text ends up on a scale. \n",
        "* List of words\n",
        "* Balance score --> nice: +2, good: +1, miserable: -4, happy: +3\n",
        "* Relies on a hand-crafted set of valence scores as dictionaries / lexicons. \n",
        "* Fails at some tasks because different words have different valences in different contexts. \n",
        "** Polarity of words may change with the topic\n",
        "** These changes can't be reflected easily in the dictionary\n",
        "** Can work fast and is less computationally resource intensive\n",
        "\n",
        "##### Example: \n",
        "Today, was, a, good, day. \n",
        "0, 0, 0, 1, 0 --> 1 - positive\n",
        "\n",
        "#### Automatic / Machine Learning\n",
        "* Modeled as a classification problem\n",
        "* Using a dataset with \"known sentiment\" we need to predict the sentence of a dataset with unknown sentiment. \n",
        "* relies on labeled historical data\n",
        "* is resource intensive (uses lots of a computer's reources to train models)\n",
        "* can be \"powerful\" (ie. goes fast and changes flexibly, depending on how it is deployed)\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "bTjqG6nd5Ker"
      },
      "source": [
        "# You will probably need to install a specific package called TextBlob to complete the following. You should be\n",
        "# able to use the following in your terminal to do so. \n",
        "conda install -c conda-forge textblob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fNEyy_MQ5Ker",
        "outputId": "63c73b0a-7037-4077-d01e-bba8f12a610c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Sentiment(polarity=0.7, subjectivity=0.6000000000000001)"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from textblob import TextBlob\n",
        "text = \"Today was a good day.\"\n",
        "my_valence = TextBlob(text)\n",
        "my_valence.sentiment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_31y3TE5Ker"
      },
      "source": [
        "THe sentiment function in TextBlob returns a tuple (that means data in pairs). Sentiment has 2 components, a _polarity_ value, and a _subjectivity_ value. Polarity is measured on a scale of -1 (negative) to 1 (positive) with 0 as a neutral value. Subjectivity, however, is measured in a range from 0 to 1. Measures the calculated degree to which a value may be accurately assessed at the assigned polarity value. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CRnNS_Ol5Ker",
        "outputId": "d32cec7b-5a0c-41c1-d714-c580ae13805c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "textblob.blob.TextBlob"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# The datatype becomes a specific thing, a textblob object that has NLP processing performed on it. \n",
        "# Sentiment is one part of the processing that we're just calling from the new textblob object.\n",
        "type(my_valence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CAPQigpc5Kes"
      },
      "outputs": [],
      "source": [
        "twocities = \"It was the best of times, it was the worst of times,it was the age of wisdom,it was the age of foolishness,it was the epoch of belief, it was the epoch of incredulity, it was the season of Light, it was the season of Darkness, it was the spring of hope, it was the winter of despair, we had everything before us, we had nothing before us, we were all going direct to Heaven, we were all going direct the other way— in short, the period was so far like the present period, that some of its noisiest authorities insisted on its being received, for good or for evil, in the superlative degree of comparison only.\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JJe6OVsK5Kez"
      },
      "outputs": [],
      "source": [
        "citiesblob = TextBlob(twocities)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y0Tap9I_5Kez",
        "outputId": "6c1be270-edb4-437c-997f-a337758516a5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Sentiment(polarity=0.022916666666666658, subjectivity=0.5895833333333332)"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "citiesblob.sentiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZEjeBojM5Kez",
        "outputId": "f76421b0-6d62-4f5a-c8cd-98ad4cc324cf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Sentiment(polarity=-0.04444444444444443, subjectivity=0.4305555555555555)"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a text string. Turn it into a TextBlob object. Call out the sentiment measures. \n",
        "tomcabin = \"Late in the afternoon of a chilly day in February, two gentlemen were sitting alone over their wine, in a well-furnished dining parlor, in the town of P----, in Kentucky. There were no servants present, and the gentlemen, with chairs closely approaching, seemed to be discussing some subject with great earnestness.\"\n",
        "tomblob = TextBlob(tomcabin)\n",
        "tomblob.sentiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pq3ir_rV5Ke0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61toXdzh5Ke0"
      },
      "source": [
        "## Questions? \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "piNr4u2c5Ke0"
      },
      "source": [
        "## Tutorials and resources for future study: \n",
        "    * https://pythonspot.com/python-sentiment-analysis/ \n",
        "    * https://github.com/nltk/nltk/wiki/Sentiment-Analysis\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tKPyOkFD5Ke0"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}